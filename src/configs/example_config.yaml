---

model: model_alias
url: https://huggingface.co/org/model_name
sampling:
  temperature: 0.7
  repetition_penalty: 1.0
  top_p: 0.95
  top_k: 40  # Applicable to llama.cpp only
  repeat_last_n: 64  # Applicable to llama.cpp only
  n_batch: 512  # Applicable to llama.cpp only
generation:
  mean_gen_len: 128  # Applicable to mlc only
  max_gen_len: 256
  max_window_size: 4096
  vocab_size: 32000  # Applicable to mlc only
prompt:  # Used in llama.cpp, taken from mlc
  conv_template: "template key from frameworks/MLC/mlc-llm/cpp/conv_templates.cc"
  text: "Your prompt text here"
  in_prefix: "<prefix>"
  in_suffix: "<suffix>"
  reverse: "<reverse_prompt>"