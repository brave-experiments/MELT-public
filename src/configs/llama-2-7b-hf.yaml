---

model: llama-2-7b-hf
url: https://huggingface.co/meta-llama/Llama-2-7b-hf
sampling:
  temperature: 0.7
  repetition_penalty: 1.0
  top_p: 0.95
  top_k: 40  # Applicable to llama.cpp only
  repeat_last_n: 64  # Applicable to llama.cpp only
  n_batch: 512  # Applicable to llama.cpp only
generation:
  mean_gen_len: 128  # Applicable to mlc only
  max_gen_len: 256
  max_window_size: 4096
  vocab_size: 32000  # Applicable to mlc only
prompt:  # Used in llama.cpp, taken from mlc
  text: ""
  in_prefix: "<s>"
  in_suffix: "</s>"
  reverse: "<s>"