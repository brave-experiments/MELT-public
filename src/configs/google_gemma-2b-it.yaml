model: google_gemma-2b-it
url: https://huggingface.co/google/gemma-2b-it
sampling:
  temperature: 0.7
  repetition_penalty: 1.0
  top_p: 0.95
  top_k: 40  # Applicable to llama.cpp only
  repeat_last_n: 64  # Applicable to llama.cpp only
  n_batch: 512  # Applicable to llama.cpp only
generation:
  mean_gen_len: 128  # Applicable to mlc only
  max_gen_len: 256
  max_window_size: 4096
  vocab_size: 256000  # Applicable to mlc only
prompt:  # Used in llama.cpp, taken from mlc
  text: "\"\""
  in_prefix: "\"<start_of_turn>user\\n\""
  in_suffix: "\"<end_of_turn>\\n\""
  reverse: "\"<start_of_turn>model\""