{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams.update({'font.size': 14})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>framework</th>\n",
       "      <th>model</th>\n",
       "      <th>dataset</th>\n",
       "      <th>quantization</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>std_err</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>paper</td>\n",
       "      <td>Llama-2-7b</td>\n",
       "      <td>winogrande</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.6920</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>paper</td>\n",
       "      <td>Llama-2-7b</td>\n",
       "      <td>arc_easy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.7520</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>paper</td>\n",
       "      <td>Llama-2-7b</td>\n",
       "      <td>arc_challenge</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.4590</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>paper</td>\n",
       "      <td>Llama-2-7b</td>\n",
       "      <td>truthfulqa_mc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3329</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>paper</td>\n",
       "      <td>Llama-2-7b</td>\n",
       "      <td>hellaswag</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.7720</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  framework       model        dataset quantization  accuracy  std_err\n",
       "0     paper  Llama-2-7b     winogrande          NaN    0.6920      NaN\n",
       "1     paper  Llama-2-7b       arc_easy          NaN    0.7520      NaN\n",
       "2     paper  Llama-2-7b  arc_challenge          NaN    0.4590      NaN\n",
       "3     paper  Llama-2-7b  truthfulqa_mc          NaN    0.3329      NaN\n",
       "4     paper  Llama-2-7b      hellaswag          NaN    0.7720      NaN"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df = pd.read_csv(\"results.csv\")\n",
    "result_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>quantization</th>\n",
       "      <th>size</th>\n",
       "      <th>size_in_memory</th>\n",
       "      <th>parameters</th>\n",
       "      <th>max_ram</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mistral-7b-v0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>14.48</td>\n",
       "      <td>13.49</td>\n",
       "      <td>7240000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mistral-7b-v0.1</td>\n",
       "      <td>q3_k</td>\n",
       "      <td>3.52</td>\n",
       "      <td>3.28</td>\n",
       "      <td>7240000</td>\n",
       "      <td>6.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mistral-7b-v0.1</td>\n",
       "      <td>q4_k</td>\n",
       "      <td>4.37</td>\n",
       "      <td>4.07</td>\n",
       "      <td>7240000</td>\n",
       "      <td>6.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mistral-7b-v0.1</td>\n",
       "      <td>q4_0</td>\n",
       "      <td>4.11</td>\n",
       "      <td>3.83</td>\n",
       "      <td>7240000</td>\n",
       "      <td>6.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mistral-7b-v0.1</td>\n",
       "      <td>AWQ</td>\n",
       "      <td>4.15</td>\n",
       "      <td>4.47</td>\n",
       "      <td>7240000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             model quantization   size  size_in_memory  parameters  max_ram\n",
       "0  Mistral-7b-v0.1         None  14.48           13.49     7240000      NaN\n",
       "1  Mistral-7b-v0.1         q3_k   3.52            3.28     7240000     6.02\n",
       "2  Mistral-7b-v0.1         q4_k   4.37            4.07     7240000     6.87\n",
       "3  Mistral-7b-v0.1         q4_0   4.11            3.83     7240000     6.61\n",
       "4  Mistral-7b-v0.1          AWQ   4.15            4.47     7240000      NaN"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "specs_df = pd.read_csv(\"model_specs.csv\")\n",
    "specs_df.loc[specs_df[\"quantization\"].isna(),\"quantization\"] = \"None\"\n",
    "specs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>framework</th>\n",
       "      <th>model</th>\n",
       "      <th>dataset</th>\n",
       "      <th>quantization</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>std_err</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>paper</td>\n",
       "      <td>Llama-2-7b</td>\n",
       "      <td>winogrande</td>\n",
       "      <td>None</td>\n",
       "      <td>0.692</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>paper</td>\n",
       "      <td>Llama-2-7b</td>\n",
       "      <td>arc_easy</td>\n",
       "      <td>None</td>\n",
       "      <td>0.752</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>paper</td>\n",
       "      <td>Llama-2-7b</td>\n",
       "      <td>arc_challenge</td>\n",
       "      <td>None</td>\n",
       "      <td>0.459</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>paper</td>\n",
       "      <td>Llama-2-7b</td>\n",
       "      <td>truthfulqa_mc</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3329</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>paper</td>\n",
       "      <td>Llama-2-7b</td>\n",
       "      <td>hellaswag</td>\n",
       "      <td>None</td>\n",
       "      <td>0.772</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  framework       model        dataset quantization accuracy std_err\n",
       "0     paper  Llama-2-7b     winogrande         None    0.692    None\n",
       "1     paper  Llama-2-7b       arc_easy         None    0.752    None\n",
       "2     paper  Llama-2-7b  arc_challenge         None    0.459    None\n",
       "3     paper  Llama-2-7b  truthfulqa_mc         None   0.3329    None\n",
       "4     paper  Llama-2-7b      hellaswag         None    0.772    None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>quantization</th>\n",
       "      <th>size</th>\n",
       "      <th>size_in_memory</th>\n",
       "      <th>parameters</th>\n",
       "      <th>max_ram</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mistral-7b-v0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>14.48</td>\n",
       "      <td>13.49</td>\n",
       "      <td>7240000</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mistral-7b-v0.1</td>\n",
       "      <td>q3_k</td>\n",
       "      <td>3.52</td>\n",
       "      <td>3.28</td>\n",
       "      <td>7240000</td>\n",
       "      <td>6.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mistral-7b-v0.1</td>\n",
       "      <td>q4_k</td>\n",
       "      <td>4.37</td>\n",
       "      <td>4.07</td>\n",
       "      <td>7240000</td>\n",
       "      <td>6.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mistral-7b-v0.1</td>\n",
       "      <td>q4_0</td>\n",
       "      <td>4.11</td>\n",
       "      <td>3.83</td>\n",
       "      <td>7240000</td>\n",
       "      <td>6.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mistral-7b-v0.1</td>\n",
       "      <td>AWQ</td>\n",
       "      <td>4.15</td>\n",
       "      <td>4.47</td>\n",
       "      <td>7240000</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             model quantization   size  size_in_memory  parameters max_ram\n",
       "0  Mistral-7b-v0.1         None  14.48           13.49     7240000    None\n",
       "1  Mistral-7b-v0.1         q3_k   3.52            3.28     7240000    6.02\n",
       "2  Mistral-7b-v0.1         q4_k   4.37            4.07     7240000    6.87\n",
       "3  Mistral-7b-v0.1         q4_0   4.11            3.83     7240000    6.61\n",
       "4  Mistral-7b-v0.1          AWQ   4.15            4.47     7240000    None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result_df.replace(np.nan, \"None\", inplace=True)\n",
    "specs_df.replace(np.nan, \"None\", inplace=True)\n",
    "display(result_df.head(5))\n",
    "display(specs_df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure pd display\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['None', 'q2_k', 'q3_k', 'q4_k', 'q4_0', 'q0f16', 'q0f32', 'AWQ',\n",
       "       'GPTQ'], dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.framework.unique()\n",
    "result_df.quantization.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['None', 'q3_k', 'q4_k', 'q4_0', 'AWQ', 'GPTQ'], dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "specs_df.quantization.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>quantization</th>\n",
       "      <th>size</th>\n",
       "      <th>size_in_memory</th>\n",
       "      <th>parameters</th>\n",
       "      <th>max_ram</th>\n",
       "      <th>framework</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mistral-7b-v0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>14.48</td>\n",
       "      <td>13.49</td>\n",
       "      <td>7240000</td>\n",
       "      <td>None</td>\n",
       "      <td>pytorch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mistral-7b-v0.1</td>\n",
       "      <td>q3_k</td>\n",
       "      <td>3.52</td>\n",
       "      <td>3.28</td>\n",
       "      <td>7240000</td>\n",
       "      <td>6.02</td>\n",
       "      <td>llamacpp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mistral-7b-v0.1</td>\n",
       "      <td>q4_k</td>\n",
       "      <td>4.37</td>\n",
       "      <td>4.07</td>\n",
       "      <td>7240000</td>\n",
       "      <td>6.87</td>\n",
       "      <td>llamacpp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mistral-7b-v0.1</td>\n",
       "      <td>q4_0</td>\n",
       "      <td>4.11</td>\n",
       "      <td>3.83</td>\n",
       "      <td>7240000</td>\n",
       "      <td>6.61</td>\n",
       "      <td>llamacpp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mistral-7b-v0.1</td>\n",
       "      <td>AWQ</td>\n",
       "      <td>4.15</td>\n",
       "      <td>4.47</td>\n",
       "      <td>7240000</td>\n",
       "      <td>None</td>\n",
       "      <td>pytorch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Mistral-7b-v0.1</td>\n",
       "      <td>GPTQ</td>\n",
       "      <td>4.16</td>\n",
       "      <td>4.47</td>\n",
       "      <td>7240000</td>\n",
       "      <td>None</td>\n",
       "      <td>pytorch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Llama-2-7b</td>\n",
       "      <td>None</td>\n",
       "      <td>13.50</td>\n",
       "      <td>12.55</td>\n",
       "      <td>6740000</td>\n",
       "      <td>None</td>\n",
       "      <td>pytorch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Llama-2-7b</td>\n",
       "      <td>q3_k</td>\n",
       "      <td>3.30</td>\n",
       "      <td>3.07</td>\n",
       "      <td>6740000</td>\n",
       "      <td>5.8</td>\n",
       "      <td>llamacpp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Llama-2-7b</td>\n",
       "      <td>q4_k</td>\n",
       "      <td>4.08</td>\n",
       "      <td>3.80</td>\n",
       "      <td>6740000</td>\n",
       "      <td>6.58</td>\n",
       "      <td>llamacpp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Llama-2-7b</td>\n",
       "      <td>q4_0</td>\n",
       "      <td>3.83</td>\n",
       "      <td>3.56</td>\n",
       "      <td>6740000</td>\n",
       "      <td>6.33</td>\n",
       "      <td>llamacpp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Llama-2-7b</td>\n",
       "      <td>AWQ</td>\n",
       "      <td>3.89</td>\n",
       "      <td>3.82</td>\n",
       "      <td>6740000</td>\n",
       "      <td>None</td>\n",
       "      <td>pytorch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Llama-2-7b</td>\n",
       "      <td>GPTQ</td>\n",
       "      <td>3.90</td>\n",
       "      <td>3.82</td>\n",
       "      <td>6740000</td>\n",
       "      <td>None</td>\n",
       "      <td>pytorch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Llama-2-13b</td>\n",
       "      <td>None</td>\n",
       "      <td>26.03</td>\n",
       "      <td>25.03</td>\n",
       "      <td>13000000</td>\n",
       "      <td>None</td>\n",
       "      <td>pytorch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Llama-2-13b</td>\n",
       "      <td>q4_k</td>\n",
       "      <td>7.87</td>\n",
       "      <td>7.33</td>\n",
       "      <td>13000000</td>\n",
       "      <td>10.37</td>\n",
       "      <td>llamacpp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Llama-2-13b</td>\n",
       "      <td>AWQ</td>\n",
       "      <td>7.25</td>\n",
       "      <td>7.08</td>\n",
       "      <td>13000000</td>\n",
       "      <td>None</td>\n",
       "      <td>pytorch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Llama-2-13b</td>\n",
       "      <td>GPTQ</td>\n",
       "      <td>7.26</td>\n",
       "      <td>7.09</td>\n",
       "      <td>13000000</td>\n",
       "      <td>None</td>\n",
       "      <td>pytorch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>TinyLlama-1.1B-v0.5</td>\n",
       "      <td>None</td>\n",
       "      <td>4.40</td>\n",
       "      <td>4.10</td>\n",
       "      <td>1100000</td>\n",
       "      <td>None</td>\n",
       "      <td>pytorch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>TinyLlama-1.1B-v0.5</td>\n",
       "      <td>q3_k</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1100000</td>\n",
       "      <td>3.05</td>\n",
       "      <td>llamacpp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>TinyLlama-1.1B-v0.5</td>\n",
       "      <td>q4_k</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.63</td>\n",
       "      <td>1100000</td>\n",
       "      <td>3.17</td>\n",
       "      <td>llamacpp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>TinyLlama-1.1B-v0.5</td>\n",
       "      <td>q4_0</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1100000</td>\n",
       "      <td>3.14</td>\n",
       "      <td>llamacpp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Zephyr-3b</td>\n",
       "      <td>None</td>\n",
       "      <td>5.59</td>\n",
       "      <td>5.37</td>\n",
       "      <td>2800000</td>\n",
       "      <td>None</td>\n",
       "      <td>pytorch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Zephyr-3b</td>\n",
       "      <td>q3_k</td>\n",
       "      <td>1.39</td>\n",
       "      <td>1.29</td>\n",
       "      <td>2800000</td>\n",
       "      <td>3.89</td>\n",
       "      <td>llamacpp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Zephyr-3b</td>\n",
       "      <td>q4_k</td>\n",
       "      <td>1.71</td>\n",
       "      <td>1.59</td>\n",
       "      <td>2800000</td>\n",
       "      <td>4.21</td>\n",
       "      <td>llamacpp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Zephyr-3b</td>\n",
       "      <td>q4_0</td>\n",
       "      <td>1.61</td>\n",
       "      <td>1.50</td>\n",
       "      <td>2800000</td>\n",
       "      <td>4.11</td>\n",
       "      <td>llamacpp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Zephyr-3b</td>\n",
       "      <td>GPTQ</td>\n",
       "      <td>1.84</td>\n",
       "      <td>1.76</td>\n",
       "      <td>2800000</td>\n",
       "      <td>None</td>\n",
       "      <td>pytorch</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  model quantization   size  size_in_memory  parameters  \\\n",
       "0       Mistral-7b-v0.1         None  14.48           13.49     7240000   \n",
       "1       Mistral-7b-v0.1         q3_k   3.52            3.28     7240000   \n",
       "2       Mistral-7b-v0.1         q4_k   4.37            4.07     7240000   \n",
       "3       Mistral-7b-v0.1         q4_0   4.11            3.83     7240000   \n",
       "4       Mistral-7b-v0.1          AWQ   4.15            4.47     7240000   \n",
       "5       Mistral-7b-v0.1         GPTQ   4.16            4.47     7240000   \n",
       "6            Llama-2-7b         None  13.50           12.55     6740000   \n",
       "7            Llama-2-7b         q3_k   3.30            3.07     6740000   \n",
       "8            Llama-2-7b         q4_k   4.08            3.80     6740000   \n",
       "9            Llama-2-7b         q4_0   3.83            3.56     6740000   \n",
       "10           Llama-2-7b          AWQ   3.89            3.82     6740000   \n",
       "11           Llama-2-7b         GPTQ   3.90            3.82     6740000   \n",
       "12          Llama-2-13b         None  26.03           25.03    13000000   \n",
       "13          Llama-2-13b         q4_k   7.87            7.33    13000000   \n",
       "14          Llama-2-13b          AWQ   7.25            7.08    13000000   \n",
       "15          Llama-2-13b         GPTQ   7.26            7.09    13000000   \n",
       "16  TinyLlama-1.1B-v0.5         None   4.40            4.10     1100000   \n",
       "17  TinyLlama-1.1B-v0.5         q3_k   0.55            0.52     1100000   \n",
       "18  TinyLlama-1.1B-v0.5         q4_k   0.67            0.63     1100000   \n",
       "19  TinyLlama-1.1B-v0.5         q4_0   0.64            0.60     1100000   \n",
       "20            Zephyr-3b         None   5.59            5.37     2800000   \n",
       "21            Zephyr-3b         q3_k   1.39            1.29     2800000   \n",
       "22            Zephyr-3b         q4_k   1.71            1.59     2800000   \n",
       "23            Zephyr-3b         q4_0   1.61            1.50     2800000   \n",
       "24            Zephyr-3b         GPTQ   1.84            1.76     2800000   \n",
       "\n",
       "   max_ram framework  \n",
       "0     None   pytorch  \n",
       "1     6.02  llamacpp  \n",
       "2     6.87  llamacpp  \n",
       "3     6.61  llamacpp  \n",
       "4     None   pytorch  \n",
       "5     None   pytorch  \n",
       "6     None   pytorch  \n",
       "7      5.8  llamacpp  \n",
       "8     6.58  llamacpp  \n",
       "9     6.33  llamacpp  \n",
       "10    None   pytorch  \n",
       "11    None   pytorch  \n",
       "12    None   pytorch  \n",
       "13   10.37  llamacpp  \n",
       "14    None   pytorch  \n",
       "15    None   pytorch  \n",
       "16    None   pytorch  \n",
       "17    3.05  llamacpp  \n",
       "18    3.17  llamacpp  \n",
       "19    3.14  llamacpp  \n",
       "20    None   pytorch  \n",
       "21    3.89  llamacpp  \n",
       "22    4.21  llamacpp  \n",
       "23    4.11  llamacpp  \n",
       "24    None   pytorch  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping_quant_framework = {\n",
    "    \"q3_k\": \"llamacpp\",\n",
    "    \"q4_0\": \"llamacpp\",\n",
    "    \"q4_k\": \"llamacpp\",\n",
    "    \"AWQ\": \"pytorch\",\n",
    "    \"GPTQ\": \"pytorch\",\n",
    "    \"None\": \"pytorch\"\n",
    "}\n",
    "specs_df[\"framework\"] = specs_df[\"quantization\"].map(mapping_quant_framework)\n",
    "specs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>framework_x</th>\n",
       "      <th>model</th>\n",
       "      <th>dataset</th>\n",
       "      <th>quantization</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>std_err</th>\n",
       "      <th>size</th>\n",
       "      <th>size_in_memory</th>\n",
       "      <th>parameters</th>\n",
       "      <th>max_ram</th>\n",
       "      <th>framework_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>paper</td>\n",
       "      <td>Llama-2-7b</td>\n",
       "      <td>winogrande</td>\n",
       "      <td>None</td>\n",
       "      <td>0.692</td>\n",
       "      <td>None</td>\n",
       "      <td>13.5</td>\n",
       "      <td>12.55</td>\n",
       "      <td>6740000</td>\n",
       "      <td>None</td>\n",
       "      <td>pytorch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>paper</td>\n",
       "      <td>Llama-2-7b</td>\n",
       "      <td>arc_easy</td>\n",
       "      <td>None</td>\n",
       "      <td>0.752</td>\n",
       "      <td>None</td>\n",
       "      <td>13.5</td>\n",
       "      <td>12.55</td>\n",
       "      <td>6740000</td>\n",
       "      <td>None</td>\n",
       "      <td>pytorch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>paper</td>\n",
       "      <td>Llama-2-7b</td>\n",
       "      <td>arc_challenge</td>\n",
       "      <td>None</td>\n",
       "      <td>0.459</td>\n",
       "      <td>None</td>\n",
       "      <td>13.5</td>\n",
       "      <td>12.55</td>\n",
       "      <td>6740000</td>\n",
       "      <td>None</td>\n",
       "      <td>pytorch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>paper</td>\n",
       "      <td>Llama-2-7b</td>\n",
       "      <td>truthfulqa_mc</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3329</td>\n",
       "      <td>None</td>\n",
       "      <td>13.5</td>\n",
       "      <td>12.55</td>\n",
       "      <td>6740000</td>\n",
       "      <td>None</td>\n",
       "      <td>pytorch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>paper</td>\n",
       "      <td>Llama-2-7b</td>\n",
       "      <td>hellaswag</td>\n",
       "      <td>None</td>\n",
       "      <td>0.772</td>\n",
       "      <td>None</td>\n",
       "      <td>13.5</td>\n",
       "      <td>12.55</td>\n",
       "      <td>6740000</td>\n",
       "      <td>None</td>\n",
       "      <td>pytorch</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  framework_x       model        dataset quantization accuracy std_err  size  \\\n",
       "0       paper  Llama-2-7b     winogrande         None    0.692    None  13.5   \n",
       "1       paper  Llama-2-7b       arc_easy         None    0.752    None  13.5   \n",
       "2       paper  Llama-2-7b  arc_challenge         None    0.459    None  13.5   \n",
       "3       paper  Llama-2-7b  truthfulqa_mc         None   0.3329    None  13.5   \n",
       "4       paper  Llama-2-7b      hellaswag         None    0.772    None  13.5   \n",
       "\n",
       "   size_in_memory  parameters max_ram framework_y  \n",
       "0           12.55     6740000    None     pytorch  \n",
       "1           12.55     6740000    None     pytorch  \n",
       "2           12.55     6740000    None     pytorch  \n",
       "3           12.55     6740000    None     pytorch  \n",
       "4           12.55     6740000    None     pytorch  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "merged_df = result_df.merge(specs_df, on=(\"model\", \"quantization\"))\n",
    "display(merged_df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>framework</th>\n",
       "      <th>model</th>\n",
       "      <th>dataset</th>\n",
       "      <th>quantization</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>std_err</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>pytorch</td>\n",
       "      <td>Llama-2-7b</td>\n",
       "      <td>arc_easy</td>\n",
       "      <td>None</td>\n",
       "      <td>0.763</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>pytorch</td>\n",
       "      <td>Llama-2-7b</td>\n",
       "      <td>winogrande</td>\n",
       "      <td>None</td>\n",
       "      <td>0.6906</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>pytorch</td>\n",
       "      <td>Llama-2-7b</td>\n",
       "      <td>truthfulqa</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3209</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>pytorch</td>\n",
       "      <td>Llama-2-7b</td>\n",
       "      <td>truthfulqa_mc_1</td>\n",
       "      <td>None</td>\n",
       "      <td>0.2521</td>\n",
       "      <td>0.0152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>pytorch</td>\n",
       "      <td>Llama-2-7b</td>\n",
       "      <td>truthfulqa_mc_2</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3897</td>\n",
       "      <td>0.0136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>pytorch</td>\n",
       "      <td>Llama-2-7b</td>\n",
       "      <td>hellaswag</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5714</td>\n",
       "      <td>0.0049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>pytorch</td>\n",
       "      <td>Mistral-7b-v0.1</td>\n",
       "      <td>arc_easy</td>\n",
       "      <td>None</td>\n",
       "      <td>0.8089</td>\n",
       "      <td>0.0081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>pytorch</td>\n",
       "      <td>Mistral-7b-v0.1</td>\n",
       "      <td>winogrande</td>\n",
       "      <td>None</td>\n",
       "      <td>0.738</td>\n",
       "      <td>0.0124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>pytorch</td>\n",
       "      <td>Mistral-7b-v0.1</td>\n",
       "      <td>truthfulqa</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3539</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>pytorch</td>\n",
       "      <td>Mistral-7b-v0.1</td>\n",
       "      <td>truthfulqa_mc_1</td>\n",
       "      <td>None</td>\n",
       "      <td>0.2815</td>\n",
       "      <td>0.0157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>pytorch</td>\n",
       "      <td>Mistral-7b-v0.1</td>\n",
       "      <td>truthfulqa_mc_2</td>\n",
       "      <td>None</td>\n",
       "      <td>0.4264</td>\n",
       "      <td>0.0142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>pytorch</td>\n",
       "      <td>Mistral-7b-v0.1</td>\n",
       "      <td>hellaswag</td>\n",
       "      <td>None</td>\n",
       "      <td>0.6127</td>\n",
       "      <td>0.0049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>pytorch</td>\n",
       "      <td>TinyLlama-1.1B-v0.5</td>\n",
       "      <td>arc_easy</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5808</td>\n",
       "      <td>0.0101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>pytorch</td>\n",
       "      <td>TinyLlama-1.1B-v0.5</td>\n",
       "      <td>winogrande</td>\n",
       "      <td>None</td>\n",
       "      <td>0.588</td>\n",
       "      <td>0.0138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>pytorch</td>\n",
       "      <td>TinyLlama-1.1B-v0.5</td>\n",
       "      <td>truthfulqa</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3029</td>\n",
       "      <td>0.0146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>pytorch</td>\n",
       "      <td>TinyLlama-1.1B-v0.5</td>\n",
       "      <td>truthfulqa_mc_1</td>\n",
       "      <td>None</td>\n",
       "      <td>0.2252</td>\n",
       "      <td>0.0146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>pytorch</td>\n",
       "      <td>TinyLlama-1.1B-v0.5</td>\n",
       "      <td>truthfulqa_mc_2</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3806</td>\n",
       "      <td>0.0145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>pytorch</td>\n",
       "      <td>TinyLlama-1.1B-v0.5</td>\n",
       "      <td>hellaswag</td>\n",
       "      <td>None</td>\n",
       "      <td>0.4556</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>pytorch</td>\n",
       "      <td>Llama-2-13b</td>\n",
       "      <td>arc_easy</td>\n",
       "      <td>None</td>\n",
       "      <td>0.7946</td>\n",
       "      <td>0.0083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>pytorch</td>\n",
       "      <td>Llama-2-13b</td>\n",
       "      <td>winogrande</td>\n",
       "      <td>None</td>\n",
       "      <td>0.7222</td>\n",
       "      <td>0.0126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>pytorch</td>\n",
       "      <td>Llama-2-13b</td>\n",
       "      <td>truthfulqa</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3143</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>pytorch</td>\n",
       "      <td>Llama-2-13b</td>\n",
       "      <td>truthfulqa_mc_1</td>\n",
       "      <td>None</td>\n",
       "      <td>0.2595</td>\n",
       "      <td>0.0153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>pytorch</td>\n",
       "      <td>Llama-2-13b</td>\n",
       "      <td>truthfulqa_mc_2</td>\n",
       "      <td>None</td>\n",
       "      <td>0.369</td>\n",
       "      <td>0.0136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>pytorch</td>\n",
       "      <td>Llama-2-13b</td>\n",
       "      <td>hellaswag</td>\n",
       "      <td>None</td>\n",
       "      <td>0.6006</td>\n",
       "      <td>0.0049</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    framework                model          dataset quantization accuracy  \\\n",
       "11    pytorch           Llama-2-7b         arc_easy         None    0.763   \n",
       "17    pytorch           Llama-2-7b       winogrande         None   0.6906   \n",
       "22    pytorch           Llama-2-7b       truthfulqa         None   0.3209   \n",
       "26    pytorch           Llama-2-7b  truthfulqa_mc_1         None   0.2521   \n",
       "27    pytorch           Llama-2-7b  truthfulqa_mc_2         None   0.3897   \n",
       "34    pytorch           Llama-2-7b        hellaswag         None   0.5714   \n",
       "38    pytorch      Mistral-7b-v0.1         arc_easy         None   0.8089   \n",
       "42    pytorch      Mistral-7b-v0.1       winogrande         None    0.738   \n",
       "46    pytorch      Mistral-7b-v0.1       truthfulqa         None   0.3539   \n",
       "50    pytorch      Mistral-7b-v0.1  truthfulqa_mc_1         None   0.2815   \n",
       "54    pytorch      Mistral-7b-v0.1  truthfulqa_mc_2         None   0.4264   \n",
       "58    pytorch      Mistral-7b-v0.1        hellaswag         None   0.6127   \n",
       "63    pytorch  TinyLlama-1.1B-v0.5         arc_easy         None   0.5808   \n",
       "68    pytorch  TinyLlama-1.1B-v0.5       winogrande         None    0.588   \n",
       "73    pytorch  TinyLlama-1.1B-v0.5       truthfulqa         None   0.3029   \n",
       "78    pytorch  TinyLlama-1.1B-v0.5  truthfulqa_mc_1         None   0.2252   \n",
       "83    pytorch  TinyLlama-1.1B-v0.5  truthfulqa_mc_2         None   0.3806   \n",
       "88    pytorch  TinyLlama-1.1B-v0.5        hellaswag         None   0.4556   \n",
       "145   pytorch          Llama-2-13b         arc_easy         None   0.7946   \n",
       "149   pytorch          Llama-2-13b       winogrande         None   0.7222   \n",
       "153   pytorch          Llama-2-13b       truthfulqa         None   0.3143   \n",
       "157   pytorch          Llama-2-13b  truthfulqa_mc_1         None   0.2595   \n",
       "158   pytorch          Llama-2-13b  truthfulqa_mc_2         None    0.369   \n",
       "165   pytorch          Llama-2-13b        hellaswag         None   0.6006   \n",
       "\n",
       "    std_err  \n",
       "11     None  \n",
       "17     None  \n",
       "22     None  \n",
       "26   0.0152  \n",
       "27   0.0136  \n",
       "34   0.0049  \n",
       "38   0.0081  \n",
       "42   0.0124  \n",
       "46     None  \n",
       "50   0.0157  \n",
       "54   0.0142  \n",
       "58   0.0049  \n",
       "63   0.0101  \n",
       "68   0.0138  \n",
       "73   0.0146  \n",
       "78   0.0146  \n",
       "83   0.0145  \n",
       "88    0.005  \n",
       "145  0.0083  \n",
       "149  0.0126  \n",
       "153    None  \n",
       "157  0.0153  \n",
       "158  0.0136  \n",
       "165  0.0049  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df[(result_df.quantization == \"None\") & (result_df.framework != 'paper') & (result_df.framework == 'pytorch')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>framework</th>\n",
       "      <th>model</th>\n",
       "      <th>dataset</th>\n",
       "      <th>quantization</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>std_err</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>llamacpp</td>\n",
       "      <td>Llama-2-7b</td>\n",
       "      <td>arc_easy</td>\n",
       "      <td>None</td>\n",
       "      <td>0.7567</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>pytorch</td>\n",
       "      <td>Llama-2-7b</td>\n",
       "      <td>arc_easy</td>\n",
       "      <td>None</td>\n",
       "      <td>0.763</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>llamacpp</td>\n",
       "      <td>Llama-2-7b</td>\n",
       "      <td>winogrande</td>\n",
       "      <td>None</td>\n",
       "      <td>0.6977</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>pytorch</td>\n",
       "      <td>Llama-2-7b</td>\n",
       "      <td>winogrande</td>\n",
       "      <td>None</td>\n",
       "      <td>0.6906</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>pytorch</td>\n",
       "      <td>Llama-2-7b</td>\n",
       "      <td>truthfulqa</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3209</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>pytorch</td>\n",
       "      <td>Llama-2-7b</td>\n",
       "      <td>truthfulqa_mc_1</td>\n",
       "      <td>None</td>\n",
       "      <td>0.2521</td>\n",
       "      <td>0.0152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>pytorch</td>\n",
       "      <td>Llama-2-7b</td>\n",
       "      <td>truthfulqa_mc_2</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3897</td>\n",
       "      <td>0.0136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>pytorch</td>\n",
       "      <td>Llama-2-7b</td>\n",
       "      <td>hellaswag</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5714</td>\n",
       "      <td>0.0049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>pytorch</td>\n",
       "      <td>Mistral-7b-v0.1</td>\n",
       "      <td>arc_easy</td>\n",
       "      <td>None</td>\n",
       "      <td>0.8089</td>\n",
       "      <td>0.0081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>pytorch</td>\n",
       "      <td>Mistral-7b-v0.1</td>\n",
       "      <td>winogrande</td>\n",
       "      <td>None</td>\n",
       "      <td>0.738</td>\n",
       "      <td>0.0124</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   framework            model          dataset quantization accuracy std_err\n",
       "10  llamacpp       Llama-2-7b         arc_easy         None   0.7567    None\n",
       "11   pytorch       Llama-2-7b         arc_easy         None    0.763    None\n",
       "16  llamacpp       Llama-2-7b       winogrande         None   0.6977    None\n",
       "17   pytorch       Llama-2-7b       winogrande         None   0.6906    None\n",
       "22   pytorch       Llama-2-7b       truthfulqa         None   0.3209    None\n",
       "26   pytorch       Llama-2-7b  truthfulqa_mc_1         None   0.2521  0.0152\n",
       "27   pytorch       Llama-2-7b  truthfulqa_mc_2         None   0.3897  0.0136\n",
       "34   pytorch       Llama-2-7b        hellaswag         None   0.5714  0.0049\n",
       "38   pytorch  Mistral-7b-v0.1         arc_easy         None   0.8089  0.0081\n",
       "42   pytorch  Mistral-7b-v0.1       winogrande         None    0.738  0.0124"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>quantization</th>\n",
       "      <th>size</th>\n",
       "      <th>size_in_memory</th>\n",
       "      <th>parameters</th>\n",
       "      <th>max_ram</th>\n",
       "      <th>framework</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mistral-7b-v0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>14.48</td>\n",
       "      <td>13.49</td>\n",
       "      <td>7240000</td>\n",
       "      <td>None</td>\n",
       "      <td>pytorch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Llama-2-7b</td>\n",
       "      <td>None</td>\n",
       "      <td>13.50</td>\n",
       "      <td>12.55</td>\n",
       "      <td>6740000</td>\n",
       "      <td>None</td>\n",
       "      <td>pytorch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Llama-2-13b</td>\n",
       "      <td>None</td>\n",
       "      <td>26.03</td>\n",
       "      <td>25.03</td>\n",
       "      <td>13000000</td>\n",
       "      <td>None</td>\n",
       "      <td>pytorch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>TinyLlama-1.1B-v0.5</td>\n",
       "      <td>None</td>\n",
       "      <td>4.40</td>\n",
       "      <td>4.10</td>\n",
       "      <td>1100000</td>\n",
       "      <td>None</td>\n",
       "      <td>pytorch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Zephyr-3b</td>\n",
       "      <td>None</td>\n",
       "      <td>5.59</td>\n",
       "      <td>5.37</td>\n",
       "      <td>2800000</td>\n",
       "      <td>None</td>\n",
       "      <td>pytorch</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  model quantization   size  size_in_memory  parameters  \\\n",
       "0       Mistral-7b-v0.1         None  14.48           13.49     7240000   \n",
       "6            Llama-2-7b         None  13.50           12.55     6740000   \n",
       "12          Llama-2-13b         None  26.03           25.03    13000000   \n",
       "16  TinyLlama-1.1B-v0.5         None   4.40            4.10     1100000   \n",
       "20            Zephyr-3b         None   5.59            5.37     2800000   \n",
       "\n",
       "   max_ram framework  \n",
       "0     None   pytorch  \n",
       "6     None   pytorch  \n",
       "12    None   pytorch  \n",
       "16    None   pytorch  \n",
       "20    None   pytorch  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(result_df[(result_df.quantization == \"None\") & (result_df.framework != 'paper')].head(10))\n",
    "display(specs_df[specs_df.quantization == \"None\"].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Llama-2-7b', 'Mistral-7b-v0.1', 'TinyLlama-1.1B-v0.5',\n",
       "       'Zephyr-3b', 'Llama-2-13b'], dtype=object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df[merged_df.quantization == \"None\"].model.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Llama-2-13b'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m6/kw74nlzd53j7nf5_4l969_0c0000gn/T/ipykernel_52271/1273996410.py:11: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df_of_interest[cols] = df_of_interest[cols].astype(np.double).applymap(lambda x: f\"{x:.2f}\" if x else 'None')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Llama-2-7b'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m6/kw74nlzd53j7nf5_4l969_0c0000gn/T/ipykernel_52271/1273996410.py:11: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df_of_interest[cols] = df_of_interest[cols].astype(np.double).applymap(lambda x: f\"{x:.2f}\" if x else 'None')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Mistral-7b-v0.1'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m6/kw74nlzd53j7nf5_4l969_0c0000gn/T/ipykernel_52271/1273996410.py:11: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df_of_interest[cols] = df_of_interest[cols].astype(np.double).applymap(lambda x: f\"{x:.2f}\" if x else 'None')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'TinyLlama-1.1B-v0.5'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m6/kw74nlzd53j7nf5_4l969_0c0000gn/T/ipykernel_52271/1273996410.py:11: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df_of_interest[cols] = df_of_interest[cols].astype(np.double).applymap(lambda x: f\"{x:.2f}\" if x else 'None')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Zephyr-3b'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m6/kw74nlzd53j7nf5_4l969_0c0000gn/T/ipykernel_52271/1273996410.py:11: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df_of_interest[cols] = df_of_interest[cols].astype(np.double).applymap(lambda x: f\"{x:.2f}\" if x else 'None')\n"
     ]
    }
   ],
   "source": [
    "# turn all floats to use 2 decimal places and display only that to string\n",
    "acc_size_df_all = merged_df.groupby([\"model\", \"quantization\", \"size_in_memory\", \"dataset\", ])[[\"accuracy\"]].sum()\n",
    "# display(acc_size_df_all)\n",
    "os.makedirs(\"latex_tables\", exist_ok=True)\n",
    "\n",
    "for model, group_df in acc_size_df_all.groupby(\"model\").groups.items():\n",
    "  display(model)\n",
    "  cols = ['size_in_memory', 'accuracy']\n",
    "  df_of_interest = acc_size_df_all.loc[group_df].reset_index()[[\"quantization\", \"size_in_memory\", \"dataset\", \"accuracy\"]]\n",
    "  df_of_interest[cols] = df_of_interest[cols].replace(\"None\", np.nan)\n",
    "  df_of_interest[cols] = df_of_interest[cols].astype(np.double).applymap(lambda x: f\"{x:.2f}\" if x else 'None')\n",
    "  df_of_interest.set_index([\"quantization\", \"size_in_memory\", \"dataset\"], inplace=True)\n",
    "\n",
    "  with open(f\"latex_tables/acc_size_df_{model}.tex\", \"w\") as f:\n",
    "    f.write(df_of_interest.to_latex().replace('_', '\\_'))\n",
    "\n",
    "with open(\"latex_tables/acc_size_df_all.tex\", \"w\") as f:\n",
    "  f.write(acc_size_df_all.to_latex().replace('_', '\\_'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "melt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
